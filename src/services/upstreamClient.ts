import axios from 'axios';
import { config } from '../config';
import { logger } from '../logger';
import type { ChatCompletionRequest, ChatCompletionMessage } from './messageBuilder';
import type { OpenAiToolCall, OpenAiToolMessage } from '../mcp/types';
import { executeMcpToolCalls } from '../mcp/toolConverter';

/**
 * ä¸Šæ¸¸å“åº”çš„æ¶ˆæ¯ç±»å‹
 */
interface ChoiceMessage {
  role: string;
  content: string | null;
  tool_calls?: OpenAiToolCall[];
}

/**
 * ä¸Šæ¸¸å“åº”ç±»å‹
 */
interface ChatCompletionResponse {
  choices: Array<{
    index: number;
    message: ChoiceMessage;
    finish_reason: string;
  }>;
  usage?: {
    prompt_tokens?: number;
    completion_tokens?: number;
    total_tokens?: number;
  };
}

/**
 * æ‰©å±•çš„å“åº”ç±»å‹ï¼ŒåŒ…å«å®Œæ•´å¯¹è¯å†å²
 */
export interface ExtendedChatCompletionResponse extends ChatCompletionResponse {
  /** å®Œæ•´çš„å¯¹è¯å†å²ï¼ˆåŒ…æ‹¬æ‰€æœ‰tool_callså’Œç»“æœï¼‰ */
  fullMessages?: Array<ChatCompletionMessage | { role: 'assistant'; content: string | null; tool_calls: OpenAiToolCall[] } | OpenAiToolMessage>;
  /** å¯¹è¯è½®æ•° */
  conversationRounds?: number;
}

const httpClient = axios.create({
  baseURL: config.upstreamBaseUrl.replace(/\/$/, ''),
  timeout: config.requestTimeoutMs,
});

let keyIndex = 0;
const pickApiKey = (): string => {
  const key = config.upstreamApiKeys[keyIndex % config.upstreamApiKeys.length];
  keyIndex = (keyIndex + 1) % config.upstreamApiKeys.length;
  if (!key) {
    throw new Error('æœªæ‰¾åˆ°å¯ç”¨çš„ä¸Šæ¸¸ API Key');
  }
  return key;
};

/**
 * å‘é€å•æ¬¡è¯·æ±‚åˆ°ä¸Šæ¸¸API
 */
async function sendSingleRequest(payload: ChatCompletionRequest, apiKey: string): Promise<ChatCompletionResponse> {
  try {
    const response = await httpClient.post<ChatCompletionResponse>('/chat/completions', payload, {
      headers: {
        Authorization: `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
    });
    return response.data;
  } catch (error) {
    if (axios.isAxiosError(error)) {
      logger.error('ä¸Šæ¸¸æ¨¡å‹å“åº”é”™è¯¯', {
        status: error.response?.status,
        data: error.response?.data,
      });
      throw new Error(
        error.response?.data?.error?.message ??
          `Upstream request failed with status ${error.response?.status ?? 'unknown'}`,
      );
    }
    logger.error('ä¸Šæ¸¸æœªçŸ¥é”™è¯¯', { message: (error as Error).message });
    throw error;
  }
}

/**
 * å¤„ç†å¸¦tool_callsçš„å¤šè½®å¯¹è¯
 * @param payload åˆå§‹è¯·æ±‚
 * @param maxRounds æœ€å¤§è½®æ¬¡ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
 */
export const requestChatCompletion = async (
  payload: ChatCompletionRequest,
  maxRounds = 5,
): Promise<ExtendedChatCompletionResponse> => {
  const apiKey = pickApiKey();
  let currentPayload = { ...payload };
  let roundCount = 0;
  let allMessages: Array<ChatCompletionMessage | { role: 'assistant'; content: string | null; tool_calls: OpenAiToolCall[] } | OpenAiToolMessage> = [...payload.messages];

  while (roundCount < maxRounds) {
    roundCount++;

    logger.info('ğŸ”„ å‘é€è¯·æ±‚åˆ°ä¸Šæ¸¸æ¨¡å‹', {
      model: currentPayload.model,
      round: roundCount,
      messageCount: currentPayload.messages.length,
      hasTools: Boolean(currentPayload.tools && currentPayload.tools.length > 0),
    });

    // å‘é€è¯·æ±‚
    const response = await sendSingleRequest(currentPayload, apiKey);

    const choice = response.choices?.[0];
    if (!choice) {
      throw new Error('ä¸Šæ¸¸å“åº”ä¸­æ²¡æœ‰choices');
    }

    const finishReason = choice.finish_reason;
    const message = choice.message;

    logger.info('âœ… ä¸Šæ¸¸æ¨¡å‹å“åº”å®Œæˆ', {
      finishReason,
      hasContent: Boolean(message.content),
      hasToolCalls: Boolean(message.tool_calls && message.tool_calls.length > 0),
      round: roundCount,
    });

    // å¦‚æœä¸æ˜¯tool_callsï¼Œç›´æ¥è¿”å›ç»“æœ
    if (finishReason !== 'tool_calls' || !message.tool_calls || message.tool_calls.length === 0) {
      logger.info('ğŸ“¨ å®Œæˆå¯¹è¯ï¼Œè¿”å›æœ€ç»ˆç»“æœ', {
        totalRounds: roundCount,
        finishReason,
      });

      // è¿”å›æ‰©å±•å“åº”ï¼ŒåŒ…å«å®Œæ•´å¯¹è¯å†å²
      const extendedResponse: ExtendedChatCompletionResponse = {
        ...response,
        conversationRounds: roundCount,
      };

      if (roundCount > 1) {
        extendedResponse.fullMessages = allMessages;
      }

      return extendedResponse;
    }

    // æ‰§è¡Œtool_calls
    logger.info('ğŸ”§ æ£€æµ‹åˆ°tool_callsï¼Œå¼€å§‹æ‰§è¡Œå·¥å…·è°ƒç”¨', {
      toolCallCount: message.tool_calls.length,
      tools: message.tool_calls.map((tc) => tc.function.name),
    });

    const toolResults: OpenAiToolMessage[] = await executeMcpToolCalls(message.tool_calls);

    // å°†assistantçš„æ¶ˆæ¯å’Œtoolç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
    const assistantMessage = {
      role: 'assistant' as const,
      content: message.content,
      tool_calls: message.tool_calls,
    };

    allMessages = [...allMessages, assistantMessage, ...toolResults];

    const newMessages: Array<ChatCompletionMessage | { role: 'assistant'; content: string | null; tool_calls: OpenAiToolCall[] } | OpenAiToolMessage> = [
      ...currentPayload.messages,
      assistantMessage,
      ...toolResults,
    ];

    // æ›´æ–°payloadï¼Œç»§ç»­ä¸‹ä¸€è½®å¯¹è¯
    currentPayload = {
      ...currentPayload,
      messages: newMessages as ChatCompletionMessage[],
    };

    logger.info('âœ¨ å·¥å…·æ‰§è¡Œå®Œæˆï¼Œç»§ç»­ä¸‹ä¸€è½®å¯¹è¯', {
      currentRound: roundCount,
      maxRounds,
      newMessageCount: newMessages.length,
    });
  }

  // è¾¾åˆ°æœ€å¤§è½®æ¬¡
  logger.warn('âš ï¸ è¾¾åˆ°æœ€å¤§å¯¹è¯è½®æ¬¡ï¼Œç»ˆæ­¢tool_callså¾ªç¯', {
    maxRounds,
  });

  throw new Error(`å¯¹è¯å·²è¾¾åˆ°æœ€å¤§è½®æ¬¡é™åˆ¶ (${maxRounds})ï¼Œå¯èƒ½å­˜åœ¨tool_callså¾ªç¯`);
};
